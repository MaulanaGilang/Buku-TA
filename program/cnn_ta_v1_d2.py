# -*- coding: utf-8 -*-
"""CNN TA v1 d2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Rbs0ElddUPIz1tzB4VAn-gmnBZ1Wl7nD
"""

import tensorflow as tf
tf.__version__

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.metrics import Precision, Recall
import os
import time
import time
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# Set the seed for TensorFlow's random number
np.random.seed(42)
tf.random.set_seed(42)

from google.colab import drive
drive.mount('/content/drive')

datasetDir = "/content/drive/MyDrive/KeperluanTA/another1/out"

train_datagen = ImageDataGenerator(
    rescale=1.0/255,
    shear_range=0.2,
    zoom_range=0.2,
    fill_mode="nearest",
    validation_split=0.1765
)

val_datagen = ImageDataGenerator(
    rescale=1.0/255,
    validation_split=0.1765
)

train_generator = train_datagen.flow_from_directory(
    datasetDir,
    target_size=(330, 540),
    batch_size=10,
    class_mode="binary",  # Set class_mode to "categorical" for multi-class classification
    color_mode="grayscale",  # Generate grayscale images
    subset="training"
)

validation_generator = val_datagen.flow_from_directory(
    datasetDir,
    target_size=(330, 540),
    batch_size=10,
    class_mode="binary",  # Set class_mode to "categorical" for multi-class classification
    color_mode="grayscale",  # Generate grayscale images
    subset="validation"
)

print(train_generator.class_indices)

train_generator.image_shape

# Now your model definition follows
model = Sequential()

# First Convolutional Block
model.add(Conv2D(32, (3, 3), activation="relu", input_shape=(330, 540, 1)))
model.add(MaxPooling2D((2, 2)))

# Second Convolutional Block
model.add(Conv2D(64, (3, 3), activation="relu"))
model.add(MaxPooling2D((2, 2)))

# Third Convolutional Block
model.add(Conv2D(128, (3, 3), activation="relu"))
model.add(MaxPooling2D((2, 2)))

# Fourth Convolutional Block
model.add(Conv2D(256, (3, 3), activation="relu"))
model.add(MaxPooling2D((2, 2)))

# Flattening and Fully Connected Layers
model.add(Flatten())
model.add(Dense(256, activation="relu"))
model.add(Dropout(0.5))  # Dropout layer to reduce overfitting
model.add(Dense(128, activation="relu"))
model.add(Dropout(0.5))  # Another dropout layer

# Output Layer for binary classification
model.add(Dense(1, activation="sigmoid"))

model.summary()

model.compile(
    optimizer="adam",
    loss="binary_crossentropy",
    metrics=["accuracy"]
)

from tensorflow.keras.callbacks import EarlyStopping

# Define EarlyStopping callback
early_stopping = EarlyStopping(
    monitor='val_loss',     # Metric to monitor
    patience=10,             # Number of epochs with no improvement after which training will be stopped
    verbose=1,              # To log when training is being stopped
    mode='min',             # Stops training when the quantity monitored has stopped decreasing
    restore_best_weights=True  # Restores model weights from the epoch with the best value of the monitored quantity
)

# Fit the model with the EarlyStopping callback
history = model.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=100,
    validation_steps=60,
    verbose=1,
    callbacks=[early_stopping]  # Include the callback in the list
)

model.evaluate(validation_generator)

model.evaluate(train_generator)

# Specify the directory path
save_dir = '/content/drive/MyDrive/KeperluanTA/another1/2rev'

# Create the directory if it doesn't exist
os.makedirs(save_dir, exist_ok=True)

# Save the model to the specified directory
model.save(save_dir + 'model.h5')

model.save("model.h5")

import matplotlib.pyplot as plt

# Plot training & validation accuracy values
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')

# Plot training & validation loss values
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')

plt.show()

import time

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# Create new generators without shuffling for evaluating confusion matrix
eval_train_generator = train_datagen.flow_from_directory(
    datasetDir,
    target_size=(330, 540),
    batch_size=10,  # Adjust this based on your setup
    class_mode="binary",  # Adjusted for binary classification
    color_mode="grayscale",
    shuffle=False,  # Important for matching predictions to labels
    subset="training"
)

eval_validation_generator = val_datagen.flow_from_directory(
    datasetDir,
    target_size=(330, 540),
    batch_size=10,  # Match the batch size used for training/validation
    class_mode="binary",  # Adjusted for binary classification
    color_mode="grayscale",
    shuffle=False,  # Important for matching predictions to labels
    subset="validation"
)
# Start timer for inference
start_time = time.time()

# Predict the data
train_predictions = model.predict(eval_train_generator, verbose=1)
validation_predictions = model.predict(eval_validation_generator, verbose=1)

# End timer and calculate inference time
inference_time = time.time() - start_time
print("Inference time for the test set: {:.2f} seconds".format(inference_time))

# Convert probabilities to binary predictions based on a 0.5 threshold
train_pred_classes = (train_predictions > 0.5).astype(int).reshape(-1)
validation_pred_classes = (validation_predictions > 0.5).astype(int).reshape(-1)

# True labels (already in binary format)
train_true_classes = eval_train_generator.classes
validation_true_classes = eval_validation_generator.classes

# Compute confusion matrices
train_cm = confusion_matrix(train_true_classes, train_pred_classes)
validation_cm = confusion_matrix(validation_true_classes, validation_pred_classes)

# Plotting the confusion matrices
fig, ax = plt.subplots(1, 2, figsize=(12, 5))

sns.heatmap(train_cm, annot=True, fmt='d', cmap='Blues', ax=ax[0])
ax[0].set_title('Training Confusion Matrix')
ax[0].set_xlabel('Predicted Labels')
ax[0].set_ylabel('True Labels')
ax[0].set_xticklabels(['Negative', 'Positive'])
ax[0].set_yticklabels(['Negative', 'Positive'])

sns.heatmap(validation_cm, annot=True, fmt='d', cmap='Greens', ax=ax[1])
ax[1].set_title('Validation Confusion Matrix')
ax[1].set_xlabel('Predicted Labels')
ax[1].set_ylabel('True Labels')
ax[1].set_xticklabels(['Negative', 'Positive'])
ax[1].set_yticklabels(['Negative', 'Positive'], va='center')

plt.tight_layout()
plt.show()

import time
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

testDir = "/content/drive/MyDrive/KeperluanTA/another1/testout"

# Set up the test data generator
test_datagen = ImageDataGenerator(rescale=1.0/255)

test_generator = test_datagen.flow_from_directory(
    testDir,  # Directory with test images
    target_size=(330, 540),
    batch_size=10,  # Adjust based on your setup
    class_mode="binary",  # Ensure this matches your label setup
    color_mode="grayscale",
    shuffle=False  # Important for matching predictions to labels
)

# Start timer for inference
start_time = time.time()

# Predict the data
test_predictions = model.predict(test_generator, verbose=1)

# End timer and calculate inference time
inference_time = time.time() - start_time
print("Inference time for the test set: {:.2f} seconds".format(inference_time))

# Convert probabilities to binary predictions based on a 0.5 threshold
test_pred_classes = (test_predictions > 0.5).astype(int).reshape(-1)

# True labels (already in binary format)
test_true_classes = test_generator.classes

# Compute the confusion matrix
test_cm = confusion_matrix(test_true_classes, test_pred_classes)

# Plotting the confusion matrix
plt.figure(figsize=(6, 5))
sns.heatmap(test_cm, annot=True, fmt='d', cmap='Purples')
plt.title('Test Confusion Matrix')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.xticks([0.5, 1.5], ['Negative', 'Positive'])
plt.yticks([0.5, 1.5], ['Negative', 'Positive'], va='center')
plt.show()

import tensorflow as tf
from tensorflow.keras.metrics import Precision, Recall

# Define a custom F1 score metric
class F1Score(tf.keras.metrics.Metric):
    def __init__(self, name='f1_score', **kwargs):
        super(F1Score, self).__init__(name=name, **kwargs)
        self.precision = Precision()
        self.recall = Recall()

    def update_state(self, y_true, y_pred, sample_weight=None):
        self.precision.update_state(y_true, y_pred, sample_weight)
        self.recall.update_state(y_true, y_pred, sample_weight)

    def result(self):
        p = self.precision.result()
        r = self.recall.result()
        return 2 * ((p * r) / (p + r + tf.keras.backend.epsilon()))

    def reset_state(self):
        self.precision.reset_state()
        self.recall.reset_state()

# Instantiate the F1Score metric for training, validation, and test
f1_score_train = F1Score()
f1_score_val = F1Score()
f1_score_test = F1Score()

# Update the state of the F1Score metric with training data
f1_score_train.update_state(train_true_classes, train_pred_classes)
# Update the state of the F1Score metric with validation data
f1_score_val.update_state(validation_true_classes, validation_pred_classes)
# Update the state of the F1Score metric with test data
f1_score_test.update_state(test_true_classes, test_pred_classes)

# Calculate and print the F1 scores
print("Calculated F1 Score for Training Set:", f1_score_train.result().numpy())
print("Calculated F1 Score for Validation Set:", f1_score_val.result().numpy())
print("Calculated F1 Score for Test Set:", f1_score_test.result().numpy())

import os
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from PIL import Image, ImageDraw

# Assuming `model` and `test_generator` have already been defined as in your original code.

# Create a directory to save the annotated images
save_dir = '/content/drive/MyDrive/Deteksi/Eks2'
os.makedirs(save_dir, exist_ok=True)

# Iterate over each batch in the test generator
for i in range(len(test_generator)):
    images, labels = test_generator.next()
    predictions = model.predict(images)
    pred_classes = (predictions > 0.5).astype(int)

    # Process each image in the batch
    for j in range(len(images)):
        # Correctly handle images based on channel information
        if images[j].shape[-1] == 3:  # Color images
            img = Image.fromarray((images[j] * 255).astype('uint8')).convert('L')
        else:  # Grayscale images, potentially with a channel dimension of 1
            # Ensure the image is 2D
            img_array = (images[j] * 255).squeeze()  # Remove singleton dimensions
            img = Image.fromarray(img_array.astype('uint8'), 'L')

        # Determine predicted class name
        predicted_label = pred_classes[j]
        predicted_class_name = "noairgap" if predicted_label == 1 else "airgap"

        # Prepare text to draw on the image
        annotation = f'Predicted class: {predicted_class_name}'

        # Draw text on the image using PIL (default font)
        draw = ImageDraw.Draw(img)
        draw.text((10, 10), annotation, fill='white')

        # Add title to the image
        plt.imshow(img, cmap='gray')  # Ensure the image is displayed as grayscale
        plt.title(f'Predicted class: {predicted_class_name}')  # Display the name of the predicted class
        plt.axis('off')

        # Get the original filename
        original_filename = test_generator.filenames[test_generator.batch_index * test_generator.batch_size + j]
        original_filename = os.path.basename(original_filename)  # Get just the file name

        # Generate new filename based on predicted class
        predicted_filename = original_filename.split('.')[0] + '_' + predicted_class_name + '.' + original_filename.split('.')[-1]

        # Save the image with the new filename
        plt.savefig(os.path.join(save_dir, predicted_filename), bbox_inches='tight', pad_inches=0)
        plt.close()

print("Images have been annotated and saved.")